"""
rag_engine.py - RAG (Retrieval-Augmented Generation) ì—”ì§„
PDF ë¬¸ì„œ ê¸°ë°˜ ì§ˆë‹µ ì‹œìŠ¤í…œ í•µì‹¬ ë¡œì§
"""

import os
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path

from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

from vector_store import QdrantVectorStore

logger = logging.getLogger(__name__)


class RAGEngine:
    """RAG ê¸°ë°˜ ì§ˆë‹µ ì—”ì§„"""
    
    def __init__(self):
        self.vector_store = QdrantVectorStore()
        self.llm = None
        self.text_splitter = None
        self.documents_loaded = False
        self._initialize_llm()
        self._initialize_text_splitter()
    
    def _initialize_llm(self):
        """OpenAI ChatGPT ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if not openai_api_key:
                raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            self.llm = ChatOpenAI(
                openai_api_key=openai_api_key,
                model_name="gpt-4o-mini",
                temperature=0.1,
                max_tokens=1000
            )
            logger.info("âœ… OpenAI ChatGPT ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ OpenAI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _initialize_text_splitter(self):
        """í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™” (í† í° ì œí•œ ê³ ë ¤)"""
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,         # 800ì ë‹¨ìœ„ë¡œ ë¶„í•  (í† í° ì ˆì•½)
            chunk_overlap=100,      # 100ì ì˜¤ë²„ë©
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
        logger.info("âœ… í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™” ì™„ë£Œ (800ì ì²­í¬)")
    
    async def initialize_documents(self):
        """PDF ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”"""
        try:
            # ì»¬ë ‰ì…˜ ìƒì„±
            if not self.vector_store.create_collection():
                raise Exception("ë²¡í„° ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨")
            
            # ê¸°ì¡´ ë¬¸ì„œê°€ ìˆëŠ”ì§€ í™•ì¸
            collection_info = self.vector_store.get_collection_info()
            if collection_info.get("points_count", 0) > 0:
                logger.info(f"ğŸ“‹ ê¸°ì¡´ ë¬¸ì„œ {collection_info['points_count']}ê°œ ë°œê²¬, ë¡œë”© ê±´ë„ˆëœ€")
                self.documents_loaded = True
                return True
            
            # PDF íŒŒì¼ ë¡œë“œ
            data_dir = Path("/app/data")  # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ
            pdf_files = list(data_dir.glob("*.pdf"))
            
            if not pdf_files:
                logger.warning("âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            all_chunks = []
            all_metadatas = []
            
            for pdf_file in pdf_files:
                logger.info(f"ğŸ“„ PDF ë¡œë”© ì¤‘: {pdf_file.name}")
                
                # PDF ë¡œë”ë¡œ ë¬¸ì„œ ë¡œë“œ
                loader = PyPDFLoader(str(pdf_file))
                documents = loader.load()
                
                # í…ìŠ¤íŠ¸ ë¶„í• 
                chunks = self.text_splitter.split_documents(documents)
                
                # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                for i, chunk in enumerate(chunks):
                    all_chunks.append(chunk.page_content)
                    all_metadatas.append({
                        "source": pdf_file.name,
                        "page": chunk.metadata.get("page", i),
                        "chunk_id": len(all_chunks) - 1
                    })
                
                logger.info(f"âœ… {pdf_file.name}: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
            
            # ë²¡í„° ì €ì¥ì†Œì— ì €ì¥
            if self.vector_store.add_documents(all_chunks, all_metadatas):
                self.documents_loaded = True
                logger.info(f"ğŸ‰ ì´ {len(all_chunks)}ê°œ ë¬¸ì„œ ì²­í¬ ë¡œë”© ì™„ë£Œ!")
                return True
            else:
                raise Exception("ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def generate_answer(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        try:
            if not self.documents_loaded:
                return {
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œê°€ ì•„ì§ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "sources": [],
                    "confidence": 0.0
                }
            
            # 1. ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
            logger.info(f"ğŸ” ì§ˆë¬¸ ê²€ìƒ‰ ì¤‘: {question[:50]}...")
            search_results = self.vector_store.search_similar(question, limit=5)
            
            if not search_results:
                return {
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "confidence": 0.0
                }
            
            # 2. ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
            context_texts = []
            sources = []
            
            for result in search_results:
                context_texts.append(f"[í˜ì´ì§€ {result['page']}] {result['text']}")
                sources.append(f"page_{result['page']}")
            
            context = "\n\n".join(context_texts)
            
            # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = """ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ ìƒë‹´ AIì…ë‹ˆë‹¤. ì œê³µëœ ì˜ë£Œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ ê·œì¹™:
1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ì˜ë£Œ ì¡°ì–¸ì´ í•„ìš”í•œ ê²½ìš° ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œí•˜ì„¸ìš”
3. ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” "ë¬¸ì„œì—ì„œ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”
4. ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”
5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”

ì°¸ê³  ë¬¸ì„œ:
{context}"""
            
            user_prompt = f"ì§ˆë¬¸: {question}"
            
            # 4. GPTë¡œ ë‹µë³€ ìƒì„±
            messages = [
                SystemMessage(content=system_prompt.format(context=context)),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm(messages)
            answer = response.content
            
            # 5. ì‹ ë¢°ë„ ê³„ì‚° (ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ ê¸°ë°˜)
            confidence = min(search_results[0]["score"], 1.0) if search_results else 0.0
            
            logger.info(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ (ì‹ ë¢°ë„: {confidence:.2f})")
            
            return {
                "answer": answer,
                "sources": list(set(sources)),  # ì¤‘ë³µ ì œê±°
                "confidence": round(confidence, 2)
            }
            
        except Exception as e:
            logger.error(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "sources": [],
                "confidence": 0.0
            }
    
    def get_status(self) -> Dict[str, Any]:
        """RAG ì—”ì§„ ìƒíƒœ ì •ë³´"""
        collection_info = self.vector_store.get_collection_info()
        
        return {
            "documents_loaded": self.documents_loaded,
            "qdrant_status": "connected" if self.vector_store.health_check() else "disconnected",
            "openai_status": "connected" if self.llm else "disconnected",
            "documents_count": collection_info.get("points_count", 0),
            "collection_info": collection_info
        }