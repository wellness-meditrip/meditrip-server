"""
main.py - Chatbot Service FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
RAG ê¸°ë°˜ ì˜ë£Œ ìƒë‹´ ì±—ë´‡ ì„œë¹„ìŠ¤
"""

import logging
import os
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

from schemas import ChatRequest, ChatResponse, HealthResponse, ErrorResponse
from rag_engine import RAGEngine

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# RAG ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
rag_engine = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    global rag_engine
    
    # ğŸš€ ì„œë¹„ìŠ¤ ì‹œì‘
    logger.info("ğŸš€ Chatbot Service ì‹œì‘ ì¤‘...")
    
    try:
        # RAG ì—”ì§„ ì´ˆê¸°í™”
        logger.info("ğŸ¤– RAG ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        rag_engine = RAGEngine()
        
        # ë¬¸ì„œ ë¡œë”©
        logger.info("ğŸ“„ ì˜ë£Œ ë¬¸ì„œ ë¡œë”© ì¤‘...")
        success = await rag_engine.initialize_documents()
        
        if success:
            logger.info("ğŸ‰ Chatbot Service ì¤€ë¹„ ì™„ë£Œ!")
        else:
            logger.warning("âš ï¸ ë¬¸ì„œ ë¡œë”© ì‹¤íŒ¨, ì œí•œëœ ê¸°ëŠ¥ìœ¼ë¡œ ì‹œì‘")
            
    except Exception as e:
        logger.error(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        # ì„œë¹„ìŠ¤ëŠ” ê³„ì† ì‹œì‘í•˜ë˜, ì—ëŸ¬ ì‘ë‹µ ì¤€ë¹„
        rag_engine = None
    
    yield  # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    
    # ğŸ›‘ ì„œë¹„ìŠ¤ ì¢…ë£Œ
    logger.info("ğŸ‘‹ Chatbot Service ì¢…ë£Œ ì¤‘...")


# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = FastAPI(
    title="Chatbot Service API",
    description="""
    **ì˜ë£Œ ìƒë‹´ ì±—ë´‡ ì„œë¹„ìŠ¤**
    
    ## ì£¼ìš” ê¸°ëŠ¥
    - **RAG ê¸°ë°˜ ì§ˆë‹µ**: ì˜ë£Œ ë¬¸ì„œ ê¸°ë°˜ ì •í™•í•œ ë‹µë³€
    -  **PDF ë¬¸ì„œ í™œìš©**: 400í˜ì´ì§€ ì˜ë£Œ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜
    -  **ìœ ì‚¬ë„ ê²€ìƒ‰**: Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í™œìš©
    -  **GPT-4o-mini ìƒì„±**: 
    
    ## ê¸°ìˆ  ìŠ¤íƒ
    - **Vector DB**: Qdrant
    - **LLM**: OpenAI GPT-4o-mini
    - **Framework**: LangChain
    - **Embeddings**: OpenAI Ada-002
    
    ## í¬íŠ¸
    - 8009 (Docker ë‚´ë¶€: 8000)
    """,
    version="1.0.0",
    contact={
        "name": "ë‚¨ë‘í˜„(kndh2914@gmail.com)",
    },
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# =============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.post("/chat", response_model=ChatResponse, tags=["Chat"])
async def chat(request: ChatRequest):
    """
    RAG ê¸°ë°˜ ì˜ë£Œ ìƒë‹´ ì§ˆë‹µ
    - ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ ì˜ë£Œ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
    """
    try:
        if not rag_engine:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="RAG ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        logger.info(f"ğŸ’¬ ìƒˆë¡œìš´ ì§ˆë¬¸: {request.question[:100]}...")
        
        # RAGë¡œ ë‹µë³€ ìƒì„±
        result = await rag_engine.generate_answer(request.question)
        
        response = ChatResponse(**result)
        logger.info(f"âœ… ë‹µë³€ ì™„ë£Œ (ì‹ ë¢°ë„: {response.confidence})")
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì±„íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )


@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check():
    """
    ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬
    - RAG ì—”ì§„, Qdrant, OpenAI ì—°ê²° ìƒíƒœ í™•ì¸
    """
    try:
        if not rag_engine:
            return JSONResponse(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                content={
                    "service": "Chatbot Service",
                    "status": "unhealthy",
                    "qdrant_status": "disconnected",
                    "openai_status": "disconnected",
                    "documents_loaded": 0,
                    "error": "RAG ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨"
                }
            )
        
        # RAG ì—”ì§„ ìƒíƒœ í™•ì¸
        status_info = rag_engine.get_status()
        
        return HealthResponse(
            service="Chatbot Service",
            status="healthy" if status_info["documents_loaded"] else "degraded",
            qdrant_status=status_info["qdrant_status"],
            openai_status=status_info["openai_status"],
            documents_loaded=status_info["documents_count"]
        )
        
    except Exception as e:
        logger.error(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={
                "service": "Chatbot Service", 
                "status": "unhealthy",
                "error": str(e)
            }
        )


@app.get("/", tags=["Info"])
async def root():
    """ì„œë¹„ìŠ¤ ê¸°ë³¸ ì •ë³´"""
    return {
        "service": "Chatbot Service",
        "status": "running",
        "version": "1.0.0",
        "description": "RAG ê¸°ë°˜ ì˜ë£Œ ìƒë‹´ ì±—ë´‡ ì„œë¹„ìŠ¤ ğŸ¤–",
        "endpoints": {
            "chat": "/chat",
            "health": "/health",
            "docs": "/docs"
        }
    }


@app.get("/info", tags=["Info"])
async def service_info():
    """ìƒì„¸ ì„œë¹„ìŠ¤ ì •ë³´"""
    status_info = rag_engine.get_status() if rag_engine else {}
    
    return {
        "service_name": "Chatbot Service",
        "version": "1.0.0",
        "description": "RAG ê¸°ë°˜ ì˜ë£Œ ìƒë‹´ ì±—ë´‡",
        "technology": {
            "llm": "OpenAI GPT-4o-mini",
            "embeddings": "OpenAI Ada-002",
            "vector_db": "Qdrant",
            "framework": "LangChain + FastAPI"
        },
        "status": status_info,
        "port": 8009
    }


# =============================================================================
# ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬
# =============================================================================

@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """HTTP ì˜ˆì™¸ ì²˜ë¦¬"""
    logger.error(f"HTTP ì—ëŸ¬: {exc.status_code} - {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=exc.detail,
            error_code=f"HTTP_{exc.status_code}"
        ).dict()
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬"""
    logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(exc)}")
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content=ErrorResponse(
            error="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            error_code="INTERNAL_ERROR"
        ).dict()
    )


# =============================================================================
# ê°œë°œ ì„œë²„ ì‹¤í–‰
# =============================================================================

if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸ”§ ê°œë°œ ëª¨ë“œë¡œ ì„œë²„ ì‹œì‘...")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )